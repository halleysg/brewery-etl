# Brewery Data Pipeline

A ETL pipeline for processing Open Brewery DB API data using Apache Airflow, PySpark, and a medallion architecture (Bronze â†’ Silver â†’ Gold layers).

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- 4GB RAM minimum
- 8GB free disk space

### Start the Pipeline

1. **Clone the repository**
   ```bash
   git clone https://github.com/halleysg/brewery-etl.git
   cd brewery-etl
   ```

2. **Build the Docker images**
   ```bash
   docker compose build
   ```

3. **Start the services**
   ```bash
   docker compose up -d
   ```

3. **Access Airflow UI**
   - URL: http://localhost:8080
   - Username: `admin`
   - Password: `admin`

4. **Activate the DAG**
   - In Airflow UI, find `brewery_etl_pipeline`
   - Toggle the DAG to "ON"
   - Click "Trigger DAG" to run manually

## ğŸ“ Project Structure

```
brewery-pipeline/
â”œâ”€â”€ compose.yml                       # Container orchestration
â”œâ”€â”€ Dockerfile                        # Airflow + PySpark image
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/           
â”‚      â””â”€â”€ brewery_pipeline.py        # Main ETL DAG
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ jobs/   
â”‚      â”œâ”€â”€ fetch_brewery_data.py      # Fetch API data 
â”‚      â”œâ”€â”€ brewery_medallion_etl.py/  # Main ETL task
â”‚   â””â”€â”€ data/   
â”‚      â”œâ”€â”€ raw/                       # Raw data landing zone
â”‚      â”œâ”€â”€ bronze/                    # Raw data ingestion
â”‚      â”œâ”€â”€ silver/                    # Cleaned/validated data
â”‚      â””â”€â”€ gold/                      # Aggregated analytics data
â””â”€â”€ logs/                             # Airflow logs
```

## ğŸ”„ Pipeline Architecture

### Data Flow
```
API Fetch â†’ Bronze Layer â†’ Silver Layer â†’ Gold Layer
```

### Layers Description

| Layer | Purpose | Data Format | Partitioning |
|-------|---------|-------------|--------------|
| **Bronze** | Raw data storage | Parquet | By load_date |
| **Silver** | Cleaned & standardized | Parquet | By brewery_type |
| **Gold** | Business aggregations | Parquet | - |

## ğŸ“Š Data Processing

### Preprocessing
- Fetches data from Open Brewery DB API
- Stores raw data as JSON file

### Bronze Layer
- Stores raw JSON as Parquet files
- Adds ingestion timestamp

### Silver Layer
- Data cleansing and standardization
- Type conversions and validation
- Data quality flag
- Deduplication

### Gold Layer
- Aggregation by type and location

## ğŸ› ï¸ Configuration

### Airflow Configuration
- **Schedule**: Daily
- **Retries**: 1
- **Retry Delay**: 5 minutes
- **Catchup**: Disabled

## ğŸ“ Usage Examples

### Check Pipeline Status
```bash
# View DAG runs
airflow dags list-runs -d brewery_etl_pipeline

# List tasks
airflow tasks list brewery_etl_pipeline
```

### Query Processed Data
```python
# Connect to data
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("QueryBrewery").getOrCreate()

# Read silver data
df = spark.read.parquet("./data/silver/breweries")
df.show()

# Read gold aggregations
agg_df = spark.read.parquet("./data/gold/brewery_summary")
agg_df.show()
```

## ğŸ” Monitoring

### Airflow UI Features
- **DAG View**: Visual representation of pipeline
- **Task Logs**: Detailed execution logs
- **Task Duration**: Performance metrics
- **XCom**: Inter-task data passing

## ğŸ“‹ API Reference

### Data Schema

**Silver Layer Schema:**
```
root
 |-- id: string
 |-- name: string (cleaned)
 |-- brewery_type: string (lowercase)
 |-- city: string (title case)
 |-- state: string (title case)
 |-- country: string (title case)
 |-- postal_code: int (digits only)
 |-- latitude: decimal
 |-- longitude: decimal
 |-- phone: bigint (digits only)
 |-- website_url: string
 |-- ingestion_timestamp: timestamp
 |-- valid_record: boolean
```

---

**Last Updated**: June 2025
**Version**: 1.0.1